###REF: https://sites.google.com/site/miningtwitter/questions/talking-about/wordclouds/comparison-cloud
#install.packages ("bitops")
#install.packages ("RCurl")
#install.packages ("rjson")
#install.packages ("twitteR")
#install.packages ("tm")
#install.packages ("Rcpp")
#install.packages ("RColorBrewer")
#install.packages ("wordcloud")
#install.packages("devtools")
library(bitops)
library(RCurl)
library(rjson)
library(twitteR)
library(tm)
library(Rcpp)
library(RColorBrewer)
library(wordcloud)
# Cargar las credenciales
consumer_key <- "xDLBeLKKZ0ploBh97ewNwS0n2"
consumer_secret <- "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR"
access_token <- "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf"
access_secret <- "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX"
setup_twitter_oauth(consumer_key, consumer_secret, access_token = access_token, access_secret = access_secret)
install.packages ("bitops")
install.packages("bitops")
install.packages("bitops")
install.packages ("bitops")
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(caTools)
library(caret)
library(e1071)
library(plyr)
library(wordcloud)
# conexion a lo datos de la api de twiter setup_twitter_oauth("consumer key", "consumer secret", "acces token", "acces token secret")
setup_twitter_oauth("zCJLnfKZ2HGKfbMZMjEjr0mpx", "zl0BwOLzTbt34MA5EqfXcLarmHYNWqXnAAuDYBBklE7AfkCeqW", "219743012-Vft2RCGVzLQnjjVJrvCnmfU2DIVfk9TH5wEnQp24", "WPGS2DwIxLvUh8T6I4S7Y6iwPFGMzQPCh6Q4XVknXxusj")
empleo <- searchTwitter("empleo", n=1000)
getwd() #retorna el directorio sobre el cual se esta trabajando
setup_twitter_oauth("zCJLnfKZ2HGKfbMZMjEjr0mpx", "zl0BwOLzTbt34MA5EqfXcLarmHYNWqXnAAuDYBBklE7AfkCeqW", "219743012-Vft2RCGVzLQnjjVJrvCnmfU2DIVfk9TH5wEnQp24", "WPGS2DwIxLvUh8T6I4S7Y6iwPFGMzQPCh6Q4XVknXxusj")
economiadigital <- searchTwitter("economia digital", n=1000)
install.packages("twitteR")
install.packages("ROAuth")
install.packages("twitteR")
setup_twitter_oauth("zCJLnfKZ2HGKfbMZMjEjr0mpx", "zl0BwOLzTbt34MA5EqfXcLarmHYNWqXnAAuDYBBklE7AfkCeqW", "219743012-Vft2RCGVzLQnjjVJrvCnmfU2DIVfk9TH5wEnQp24", "WPGS2DwIxLvUh8T6I4S7Y6iwPFGMzQPCh6Q4XVknXxusj")
economiadigital <- searchTwitter("economiadigital", n=1000)
setup_twitter_oauth("r51oIoQdGaKsN30Hx8TvmU5Z8", "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq", "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E", "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5")
necesidadesTI <- searchTwitter("tic", n=1000)
getwd() #retorna el directorio sobre el cual se esta trabajando
setup_twitter_oauth("xDLBeLKKZ0ploBh97ewNwS0n2", "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR", "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf", "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX")
necesidadesTI <- searchTwitter("tic", n=1000)
library(ROAuth)
setup_twitter_oauth("xDLBeLKKZ0ploBh97ewNwS0n2", "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR", "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf", "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX")
necesidadesTI <- searchTwitter("tic", n=1000)
consumer_key <- "xDLBeLKKZ0ploBh97ewNwS0n2"
consumer_secret <- "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR"
access_token <- "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf"
access_secret <- "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX"
setup_twitter_oauth(consumer_key, consumer_secret, access_token = access_token, access_secret = access_secret)
setup_twitter_oauth("xDLBeLKKZ0ploBh97ewNwS0n2", "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR", "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf", "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX")
tic <- searchTwitter("tic", n=1000)
setup_twitter_oauth("xDLBeLKKZ0ploBh97ewNwS0n2", "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR", "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf", "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX")
empleo <- searchTwitter("empleo", n=1000)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(caTools)
library(caret)
library(e1071)
library(plyr)
library(wordcloud)
setup_twitter_oauth("xDLBeLKKZ0ploBh97ewNwS0n2", "rrXdQ9td3SvvBPhuWZjvLydJyl2dluCuArCkCw33mjl1c66dIR", "287563401-5kf26pBj3idOJTuPaNjeynrWGjn27734yD3kMGmf", "ekdocOoIQU0e0NRIqa4heqJh6Cc4896GgcHx0VvVs4AuX")
empleo <- searchTwitter("empleo", n=1000)
getwd() #retorna el directorio sobre el cual se esta trabajando
getwd() #retorna el directorio sobre el cual se esta trabajando
table(empleo$sentiment)
Corpus - Corpus(VectorSource(empleo$text))
install.packages(c("dplyr", "git2r", "mime", "pillar", "remotes", "rlang"))
View(empleo)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(caTools)
library(caret)
library(e1071)
library(plyr)
library(wordcloud)
consumer_key <- "r51oIoQdGaKsN30Hx8TvmU5Z8"
consumer_secret <- "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq"
access_token <- "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E"
access_secret <- "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5"
setup_twitter_oauth("consumer_key", "consumer_secret", "acces_token", "acces_secret")
consumer_key <- "r51oIoQdGaKsN30Hx8TvmU5Z8"
consumer_secret <- "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq"
access_token <- "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E"
access_secret <- "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5"
setup_twitter_oauth("consumer_key", "consumer_secret", "access_token", "access_secret")
consumer_key <- "r51oIoQdGaKsN30Hx8TvmU5Z8"
consumer_secret <- "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq"
access_token <- "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E"
access_secret <- "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
updateR()
q()
q()
shiny::runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
shiny::runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
shiny::runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
wordcloud(positivas$Palabras, positivas$frecuencia, random.order = FALSE, colors = brewer.pal(8,"Dark2"), max.words = 300)
# install.packages("tm")
# install.packages("SnowballC")
# install.packages("caTools")
# install.packages("caret")
# install.packages("e1071")
# install.packages("plyr")
#install.packages("magrittr") # Solo se necesita la primera vez que lo usas.
#install.packages("dplyr")    # InstalaciÃƒÂ³n alternativa del%>%
# install.packages("wordcloud")
# install.packages("RColorBrewer")
#install.packages("ggplot2")
library(tm) # para mineria de texto
library(SnowballC) # para reducir una palabra a su raÃƒ­z
library(caTools)
library(caret) # ordenar datos
library(e1071) # machine learning
library(plyr)
library(magrittr) # need to run every time you start R and want to use %>%
library(dplyr)    # alternative, this also loads %>%
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
# posicionamiento del directorio de trabajo
setwd("D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/Dataset")
#retorna el directorio sobre el cual se esta trabajando
getwd()
importdata <- read.csv("Prueba2.csv", sep =";") #cargar los datos al objeto tweets ("nombre del archivo.csv", separador)
table(importdata$sentiment) #Cuantos tweets positivos y negativos hay
Corpus= Corpus(VectorSource(importdata$text)) #objeto corpus se le asigna el objeto de tweets // lee los tweets
length(Corpus) #cuenta las palabras tiene el corpus
content(Corpus[[50]]) #imprime la posicion 50
#Preprocesamiento
# Corpus <- tm_map(Corpus, gsub("[[:cntrl:]]", " "))  # Eliminar caracteres especiales de la codificaci?n, como saltos de l?nea y tabulaciones
# Corpus <- tm_map(tolower(Corpus))  # cambia las palabras a minusculas
# Corpus <- tm_map(removeWords(Corpus, words = stopwords("spanish"))) # eliminar palabras vacias, preposiciones y muletillas
# Corpus <- tm_map(removePunctuation(Corpus)) #Elimna la puntuacion
# Corpus <- tm_map(removeNumbers(Corpus)) #Elimna numeros
# Corpus <- tm_map(stripWhitespace(Corpus)) # Elimina espacios vacios excesivos
# Corpus <- tm_map(stemDocument(Corpus)) #acorta las palabras a su raiz "devolvieron" "devolver"
Corpus <- tm_map(Corpus, PlainTextDocument)  # vuelve el corpus normal para poder visualizarlo
#removeURL <- content_transformer(function(x) gsub("(f|ht)tp(s?)://\\S+", "", x, perl=T)) # funci?n para eliminar http
Corpus <- tm_map(Corpus, removeURL) # Elimina las palabras que empiezan por "http." seguidas de cualquier cosa que no sea un espacio)
content(Corpus[[50]]) #imprime la posicion 50
Corpus <- tm_map(Corpus, removePunctuation) #quita la puntuacion
content(Corpus[[50]]) #imprime la posicion 50
Corpus <- tm_map(Corpus, removeNumbers) #quita los numeros
content(Corpus[[50]]) #imprime la posicion 50
Corpus <- tm_map(Corpus, content_transformer(tolower)) #procesamiento cambia las palabras a minusculas
content(Corpus[[50]]) #imprime la posicion 50
stopwords("spanish")[1:50] #preposiciones etc... [1:50] imprime las 50 primeras / stopwords("spanish")
Corpus <- tm_map(Corpus, removeWords, c(stopwords("spanish"), "las", "tendencias")) #remueve las stopwords y otras palabras que se deseen
content(Corpus[[50]]) #imprime la posicion 50
Corpus <- tm_map(Corpus, stemDocument,language="spanish")  #acorta las palabras a su raiz "devolvieron" "devolver"
content(Corpus[[50]]) #imprime la posicion 50
Corpus <- tm_map(Corpus, stripWhitespace) #quita los espacios vacios excesivos
content(Corpus[[50]]) #imprime la posicion 50
#clasificaci?n
frequencies <- DocumentTermMatrix(Corpus)  #crear matriz de palabras
frequencies #imprime atributos de frequencies de la matriz; Documents= Filas -twetts, terms= palabras - columnas
inspect(frequencies[15:20, 5:10]) #zoop de la matriz / posiciones [15:20, 5:10]
findFreqTerms(frequencies, lowfreq = 50) # Ver Palabras con mayor frecuencias -- iguales o mayores a 50
sparse <- removeSparseTerms(frequencies, 0.995) #quitar palabras que son mencionadas muy poco / deja las palabras mas usadas
sparse #imprime sparse  -- sparce=palabras que aparecen poco
tweetsSparse <- as.data.frame(as.matrix(sparse)) # retornar la variable sparse como una base de datos en formato R
colnames(tweetsSparse) = make.names(colnames(tweetsSparse)) #asinar los nombres de cada palabra al dataframe
tweetsSparse$sentiment <- importdata$sentiment #examina con la base de datos de sentimientos precargada
#modelo de clasificaci?n
#Objetivo: Encontrar  un hiperplano h de dimension (n-1) que separe los ejemplos etiquetados con -1 de los etiquetados con +1
#con un "margen maximo" (P).
#los SVM buscan los puntos mas cercanos entre varias clases. Estos puntos se llaman "los vectores de soporte"
#SVM luego declara que la mejor linea de separaci?n va a ser la linea que divide las dos clases y que al mismo tiempo
#maximiza la distancia del hiperplano a los vectores de soporte (r)
#Ecuaci?n del hiperplano: WX+b=0
#Problema de optimizaci?n: Encuentre W y b  tal que  P=2/[[W]]
#partir la base de datos en entrenamiento y evaluaci?n
#(entrenamiento: ense?arle a la BD como funcionar, evaluaci?n: evaluar como lo hace el modelo y su poder de predicci?n)
set.seed(12)
split <- sample.split(tweetsSparse$sentiment, SplitRatio = 0.8) #decide que observaciones se van para un lado u otro
#plitRatio= 0.8 / el 805 se va a entrenamiento
trainSparse = subset(tweetsSparse, split==TRUE) #particion modelo de entrenamiento
TestSparse = subset(tweetsSparse, split==FALSE) #particion  modelo de evaluaci?n
table(TestSparse$sentiment)
165/328
#algoritmo de clasificacion
# Se debe cargar: library(caret); library(e1071), library(plyr)
SVM <- svm(as.factor(sentiment)~ ., data=trainSparse)  # Entrena al modelo soporte vector machine
summary(SVM) #Describe el modelo
predictSVM <- predict(SVM, newdata = TestSparse)
confusionMatrix(predictSVM,as.factor(TestSparse$sentiment)) #evaluar el desempe?o de los tweets
# ahora se va a crear una nube con las palabras mas repetidas
positive <- subset(tweetsSparse, tweetsSparse$sentiment==1) #crea base de datos de tweets positivos
positive$sentiment <- NULL # Eliminamos la variable sentiment porque no se necesita en la nube de palabras
positivas <- as.data.frame(colSums(positive)) #generar frecuencias de las palabras positivas -- suma de columnas (cada palabra)
positivas$words <- row.names(positivas) #crea variable que se llame words
colnames(positivas) <- c("frecuencia","Palabras")
table(positivas)
# Crear una nube de palabras
# Se debe cargar:
# library(wordcloud)
# library("RColorBrewer")
wordcloud(positivas$Palabras, positivas$frecuencia, random.order = FALSE, colors = brewer.pal(8,"Dark2"), max.words = 300)
# Crear histograma de frecuencia de palabras
hist(positivas$frecuencia, main ="Frecuencia de palabras positivas", xlab = "Palabras mÃƒÂ¡s utilizadas" , ylab = "Frecuencia", col ="light blue",breaks = "Sturges")
#GrÃƒÂ¡ficas de frecuencia
# positivas[1:10, ] %>%
#   ggplot(aes(Palabras, frecuencia)) +
#   geom_bar(stat = "identity", color = "black", fill = "#87CEFA") +
#   geom_text(aes(hjust = 1.3, label = frec)) +
#   coord_flip() +
#   labs(title = "Diez palabras mÃƒÂ¡s frecuentes en Niebla",  x = "Palabras", y = "NÃƒÂºmero de usos")
# Muestra resumen = valor min, mÃƒÂ¡ximo; mediana, moda; 1 y 3 quartil
summary(positivas)
# tweets_tidy %>%  ggplot(aes(x = Palabras)) + geom_bar() + coord_flip() + theme_bw()
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
table(importdata$sentiment) #Cuantos tweets positivos y negativos hay
importdata <- read.csv("Prueba2.csv", sep =";") #cargar los datos al objeto tweets ("nombre del archivo.csv", separador)
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp()
runApp()
runApp()
runApp()
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp()
runApp()
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp()
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
# install.packages("twitteR")
# install.packages("ROAuth")
# install.packages("httr")
# install.packages("tm")
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
# conexion a los datos de la api de twiter setup_twitter_oauth("consumer key", "consumer secret", "acces token", "acces token secret")
consumer_key <- "r51oIoQdGaKsN30Hx8TvmU5Z8"
consumer_secret <- "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq"
access_token <- "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E"
access_secret <- "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
#Seleccionamos tweets o la busqueda a realizar
consulta <- searchTwitter("seguridad sistemas", n=1000)
#Creando un dataset de los datos obtenidos
Lista=twitteR::twListToDF(consulta)
#Establezco el directorio de trabajo
setwd("D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/Dataset")
#Exportando datos
write.csv(Lista, file="bd_descarga.csv",row.names = F)
# install.packages("twitteR")
# install.packages("ROAuth")
# install.packages("httr")
# install.packages("tm")
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
# conexion a los datos de la api de twiter setup_twitter_oauth("consumer key", "consumer secret", "acces token", "acces token secret")
consumer_key <- "r51oIoQdGaKsN30Hx8TvmU5Z8"
consumer_secret <- "eVB9Vw2qTqjB7PQ7RVGNCGLjz6UNam3nqbkviDEoYsvV1hVHDq"
access_token <- "219743012-efZ5bpOckPPxIqr3TL1TBuEj0CYLvf9ynDZThY4E"
access_secret <- "GVB3RzuGzK9tUiGHttiWpCJK1eKTn0L9eNuMwPngmcZr5"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
#Seleccionamos tweets o la busqueda a realizar
consulta <- searchTwitter("seguridad sistemas", n=1000)
#Creando un dataset de los datos obtenidos
Lista=twitteR::twListToDF(consulta)
#Establezco el directorio de trabajo
setwd("D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/Dataset")
#Exportando datos
write.csv(Lista, file="bd_descarga.csv",row.names = F)
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
runApp('D:/Estudios/UNAD/Trabajo de grado/Proyecto final/Proyecto R-Twitter/analisis_sentimientos/Interfaz_usuario')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
